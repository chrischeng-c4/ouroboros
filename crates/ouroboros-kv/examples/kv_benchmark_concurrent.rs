//! Fixed concurrent benchmark suite for KV store
//!
//! This benchmark correctly measures concurrent performance by:
//! 1. Creating the engine once (outside timed section)
//! 2. Using thread pools to avoid spawn overhead
//! 3. Measuring only actual operations

use ouroboros_kv::engine::KvEngine;
use ouroboros_kv::types::{KvKey, KvValue};
use ouroboros_qc::benchmark::{
    Benchmarker, BenchmarkConfig, BenchmarkReport, BenchmarkReportGroup, BenchmarkEnvironment,
};
use std::sync::{Arc, Barrier};
use std::thread;
use std::time::Instant;

/// Format number with thousands separator
fn format_number(n: f64) -> String {
    let n_int = n as u64;
    let s = n_int.to_string();
    let bytes = s.as_bytes();
    let mut result = String::new();

    for (i, &b) in bytes.iter().enumerate() {
        if i > 0 && (bytes.len() - i) % 3 == 0 {
            result.push(',');
        }
        result.push(b as char);
    }
    result
}

/// Helper to create a key for benchmarks
fn make_key(id: usize) -> KvKey {
    KvKey::new(format!("bench_key_{}", id)).unwrap()
}

/// Helper to create a string value
fn make_string_value(id: usize) -> KvValue {
    KvValue::String(format!("value_{}", id))
}

/// Benchmark concurrent SET operations with proper methodology
fn bench_concurrent_set(num_threads: usize, ops_per_thread: usize, engine: &Arc<KvEngine>) -> (f64, f64) {
    let barrier = Arc::new(Barrier::new(num_threads + 1)); // +1 for coordinator
    let mut handles = vec![];

    // Spawn persistent threads
    for thread_id in 0..num_threads {
        let engine = Arc::clone(engine);
        let barrier = Arc::clone(&barrier);

        handles.push(thread::spawn(move || {
            // Wait for all threads to be ready
            barrier.wait();

            // Perform operations (timed by coordinator)
            for i in 0..ops_per_thread {
                let key = make_key(thread_id * 1_000_000 + i);
                let value = make_string_value(i);
                engine.set(&key, value, None);
            }
        }));
    }

    // Coordinator: start timing when all threads are ready
    barrier.wait();
    let start = Instant::now();

    // Wait for all threads to complete
    for handle in handles {
        handle.join().unwrap();
    }

    let elapsed = start.elapsed();
    let total_ops = (num_threads * ops_per_thread) as f64;
    let ops_per_sec = total_ops / elapsed.as_secs_f64();

    (ops_per_sec, elapsed.as_secs_f64())
}

/// Benchmark concurrent GET operations
fn bench_concurrent_get(num_threads: usize, ops_per_thread: usize, engine: &Arc<KvEngine>) -> (f64, f64) {
    // Pre-populate data
    for i in 0..10_000 {
        let key = make_key(i);
        let value = make_string_value(i);
        engine.set(&key, value, None);
    }

    let barrier = Arc::new(Barrier::new(num_threads + 1));
    let mut handles = vec![];

    for thread_id in 0..num_threads {
        let engine = Arc::clone(engine);
        let barrier = Arc::clone(&barrier);

        handles.push(thread::spawn(move || {
            barrier.wait();

            for i in 0..ops_per_thread {
                let key = make_key((thread_id * ops_per_thread + i) % 10_000);
                let _ = engine.get(&key);
            }
        }));
    }

    barrier.wait();
    let start = Instant::now();

    for handle in handles {
        handle.join().unwrap();
    }

    let elapsed = start.elapsed();
    let total_ops = (num_threads * ops_per_thread) as f64;
    let ops_per_sec = total_ops / elapsed.as_secs_f64();

    (ops_per_sec, elapsed.as_secs_f64())
}

/// Benchmark concurrent INCR operations
fn bench_concurrent_incr(num_threads: usize, ops_per_thread: usize, engine: &Arc<KvEngine>) -> (f64, f64) {
    // Create shared counters
    let num_counters = 100;
    for i in 0..num_counters {
        let key = make_key(i);
        engine.set(&key, KvValue::Int(0), None);
    }

    let barrier = Arc::new(Barrier::new(num_threads + 1));
    let mut handles = vec![];

    for thread_id in 0..num_threads {
        let engine = Arc::clone(engine);
        let barrier = Arc::clone(&barrier);

        handles.push(thread::spawn(move || {
            barrier.wait();

            for i in 0..ops_per_thread {
                let key = make_key((thread_id + i) % num_counters);
                let _ = engine.incr(&key, 1);
            }
        }));
    }

    barrier.wait();
    let start = Instant::now();

    for handle in handles {
        handle.join().unwrap();
    }

    let elapsed = start.elapsed();
    let total_ops = (num_threads * ops_per_thread) as f64;
    let ops_per_sec = total_ops / elapsed.as_secs_f64();

    // Verify correctness
    let expected_sum: i64 = (num_threads * ops_per_thread) as i64;
    let mut actual_sum: i64 = 0;
    for i in 0..num_counters {
        let key = make_key(i);
        if let Some(KvValue::Int(n)) = engine.get(&key) {
            actual_sum += n;
        }
    }
    assert_eq!(actual_sum, expected_sum, "INCR operations lost updates!");

    (ops_per_sec, elapsed.as_secs_f64())
}

/// Benchmark mixed workload (50% GET, 50% SET)
fn bench_concurrent_mixed(num_threads: usize, ops_per_thread: usize, engine: &Arc<KvEngine>) -> (f64, f64) {
    // Pre-populate
    for i in 0..1_000 {
        let key = make_key(i);
        let value = make_string_value(i);
        engine.set(&key, value, None);
    }

    let barrier = Arc::new(Barrier::new(num_threads + 1));
    let mut handles = vec![];

    for thread_id in 0..num_threads {
        let engine = Arc::clone(engine);
        let barrier = Arc::clone(&barrier);

        handles.push(thread::spawn(move || {
            barrier.wait();

            for i in 0..ops_per_thread {
                if i % 2 == 0 {
                    // GET
                    let key = make_key((thread_id * ops_per_thread + i) % 1_000);
                    let _ = engine.get(&key);
                } else {
                    // SET
                    let key = make_key((thread_id * ops_per_thread + i) % 1_000);
                    let value = make_string_value(i);
                    engine.set(&key, value, None);
                }
            }
        }));
    }

    barrier.wait();
    let start = Instant::now();

    for handle in handles {
        handle.join().unwrap();
    }

    let elapsed = start.elapsed();
    let total_ops = (num_threads * ops_per_thread) as f64;
    let ops_per_sec = total_ops / elapsed.as_secs_f64();

    (ops_per_sec, elapsed.as_secs_f64())
}

/// Wrapper to convert throughput test to benchmarker format
fn run_throughput_test<F>(
    benchmarker: &Benchmarker,
    name: &str,
    num_threads: usize,
    ops_per_thread: usize,
    engine: &Arc<KvEngine>,
    test_fn: F,
) -> ouroboros_qc::benchmark::BenchmarkResult
where
    F: Fn(usize, usize, &Arc<KvEngine>) -> (f64, f64),
{
    let config = benchmarker.config();
    let rounds = config.rounds as usize;
    let mut times_ms = Vec::with_capacity(rounds);

    // Warmup
    for _ in 0..config.warmup {
        let _ = test_fn(num_threads, ops_per_thread, engine);
    }

    // Timed runs
    for _ in 0..rounds {
        let (ops_per_sec, elapsed_secs) = test_fn(num_threads, ops_per_thread, engine);
        // Store the time per operation batch
        let time_ms = elapsed_secs * 1000.0;
        times_ms.push(time_ms);

        // Print intermediate result
        println!("    {} threads: {:>12} ops/sec ({:.3}s)",
                 num_threads, format_number(ops_per_sec), elapsed_secs);
    }

    let stats = ouroboros_qc::benchmark::BenchmarkStats::from_times(
        times_ms,
        1,
        config.rounds,
        config.warmup,
    );

    ouroboros_qc::benchmark::BenchmarkResult::success(name, stats)
}

/// Benchmark scalability: measure how performance scales with thread count
fn bench_scalability_analysis(engine: &Arc<KvEngine>) {
    println!("\n=== Scalability Analysis ===\n");
    println!("Operations per thread: 100,000");
    println!();

    let ops_per_thread = 100_000;
    let thread_counts = vec![1, 2, 4, 8, 16];

    for &num_threads in &thread_counts {
        let (ops_per_sec, elapsed) = bench_concurrent_mixed(num_threads, ops_per_thread, engine);
        let total_ops = num_threads * ops_per_thread;
        let speedup = if num_threads == 1 {
            1.0
        } else {
            ops_per_sec / 3_500_000.0 // Approximate single-thread baseline
        };

        println!("{:2} threads: {:>12} ops/sec ({:>10} total ops, {:.3}s) [Speedup: {:.2}x]",
                 num_threads, format_number(ops_per_sec), format_number(total_ops as f64), elapsed, speedup);
    }
}

fn main() {
    println!("\n=== KV Store Concurrent Benchmark Suite (FIXED) ===\n");

    // Create engine once
    let engine = Arc::new(KvEngine::new());

    // Use quick config for faster results
    let benchmarker = Benchmarker::new(BenchmarkConfig::new(1, 5, 2));

    let mut report = BenchmarkReport::new("KV Store Concurrent Performance (Fixed)");
    report = report.with_description(
        "Corrected concurrent benchmarks measuring actual throughput without thread spawning overhead"
    );

    // Set environment info
    let env = BenchmarkEnvironment {
        rust_version: Some(env!("CARGO_PKG_RUST_VERSION").to_string()),
        platform: Some(std::env::consts::OS.to_string()),
        cpu: Some(format!("{} cores", num_cpus::get())),
        hostname: hostname::get().ok().and_then(|h| h.into_string().ok()),
        python_version: None,
    };
    report.set_environment(env);

    // Group 1: SET operations
    println!("\nRunning Concurrent SET benchmarks...");
    let mut group1 = BenchmarkReportGroup::new("Concurrent SET Operations");
    group1 = group1.with_baseline("set_2_threads");

    let ops_per_thread = 100_000;

    group1.add_result(run_throughput_test(
        &benchmarker, "set_2_threads", 2, ops_per_thread, &engine, bench_concurrent_set
    ));
    group1.add_result(run_throughput_test(
        &benchmarker, "set_4_threads", 4, ops_per_thread, &engine, bench_concurrent_set
    ));
    group1.add_result(run_throughput_test(
        &benchmarker, "set_8_threads", 8, ops_per_thread, &engine, bench_concurrent_set
    ));

    report.add_group(group1);

    // Group 2: GET operations
    println!("\nRunning Concurrent GET benchmarks...");
    let mut group2 = BenchmarkReportGroup::new("Concurrent GET Operations");
    group2 = group2.with_baseline("get_2_threads");

    group2.add_result(run_throughput_test(
        &benchmarker, "get_2_threads", 2, ops_per_thread, &engine, bench_concurrent_get
    ));
    group2.add_result(run_throughput_test(
        &benchmarker, "get_4_threads", 4, ops_per_thread, &engine, bench_concurrent_get
    ));
    group2.add_result(run_throughput_test(
        &benchmarker, "get_8_threads", 8, ops_per_thread, &engine, bench_concurrent_get
    ));

    report.add_group(group2);

    // Group 3: INCR operations (atomic, high contention)
    println!("\nRunning Concurrent INCR benchmarks...");
    let mut group3 = BenchmarkReportGroup::new("Concurrent INCR Operations (Atomic)");
    group3 = group3.with_baseline("incr_2_threads");

    group3.add_result(run_throughput_test(
        &benchmarker, "incr_2_threads", 2, ops_per_thread, &engine, bench_concurrent_incr
    ));
    group3.add_result(run_throughput_test(
        &benchmarker, "incr_4_threads", 4, ops_per_thread, &engine, bench_concurrent_incr
    ));
    group3.add_result(run_throughput_test(
        &benchmarker, "incr_8_threads", 8, ops_per_thread, &engine, bench_concurrent_incr
    ));

    report.add_group(group3);

    // Group 4: Mixed workload
    println!("\nRunning Concurrent Mixed workload benchmarks...");
    let mut group4 = BenchmarkReportGroup::new("Concurrent Mixed Workload (50% GET, 50% SET)");
    group4 = group4.with_baseline("mixed_2_threads");

    group4.add_result(run_throughput_test(
        &benchmarker, "mixed_2_threads", 2, ops_per_thread, &engine, bench_concurrent_mixed
    ));
    group4.add_result(run_throughput_test(
        &benchmarker, "mixed_4_threads", 4, ops_per_thread, &engine, bench_concurrent_mixed
    ));
    group4.add_result(run_throughput_test(
        &benchmarker, "mixed_8_threads", 8, ops_per_thread, &engine, bench_concurrent_mixed
    ));

    report.add_group(group4);

    // Scalability analysis
    bench_scalability_analysis(&engine);

    // Print detailed report to console
    println!("\n{}", report.to_console());

    // Generate outputs
    println!("\nGenerating reports...");

    // Write JSON report
    std::fs::write("kv_benchmark_concurrent_fixed.json", report.to_json())
        .expect("Failed to write JSON report");
    println!("  JSON report: kv_benchmark_concurrent_fixed.json");

    // Write HTML report
    std::fs::write("kv_benchmark_concurrent_fixed.html", report.to_html())
        .expect("Failed to write HTML report");
    println!("  HTML report: kv_benchmark_concurrent_fixed.html");

    // Write Markdown report
    std::fs::write("kv_benchmark_concurrent_fixed.md", report.to_markdown())
        .expect("Failed to write Markdown report");
    println!("  Markdown report: kv_benchmark_concurrent_fixed.md");

    println!("\nFixed concurrent benchmark suite completed!");
}
